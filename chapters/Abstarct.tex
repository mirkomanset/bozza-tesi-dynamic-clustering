% ABSTRACT IN ENGLISH

\chapter*{Abstract}
Machine Learning (ML) has become a cornerstone technology for extracting insights
and enabling decision-making across various domains. However, real-world data
often exhibit non-stationary behavior, where underlying distributions shift over
time, causing performance degradation in ML models. Detecting and explaining
these changes, commonly known as data drift, is critical for maintaining
reliable systems in evolving environments.

This thesis focuses on the explainability of drift through a novel framework
for dynamic clustering, which models and interprets changes in cluster
structures across temporal data snapshots. Unlike traditional static clustering
methods, the proposed approach captures the evolution of clusters by
identifying transitions and providing interpretable representations of
structural changes.

The framework's modular and algorithm-agnostic design facilitates its
application across different domains and clustering algorithms. Experimental
results on both synthetic and real-world datasets validate its effectiveness in
enhancing the understanding of data dynamics, thereby supporting better
adaptation of ML models in non-stationary settings.

By contributing to drift explainability, this work aims to improve the
transparency and robustness of ML applications operating in dynamic and complex
environments. \\ \\ \textbf{Keywords:} Machine Learning, Concept Drift,
Non-Stationarity, Clustering, Explainaiblity % Keywords

% ABSTRACT IN ITALIAN

\chapter*{Abstract in lingua italiana}
Il Machine Learning (ML) è diventato una tecnologia fondamentale per l'estrazione 
di conoscenza e il supporto alle decisioni in diversi ambiti applicativi. 
Tuttavia, i dati reali presentano spesso comportamenti non stazionari, in cui le 
distribuzioni sottostanti cambiano nel tempo, causando un degrado delle 
prestazioni dei modelli di ML.\@ Rilevare e spiegare questi cambiamenti, noti come 
drift dei dati, è cruciale per mantenere sistemi affidabili in ambienti in 
evoluzione.

Questa tesi si concentra sulla spiegabilità del drift attraverso un nuovo
framework per il clustering dinamico, che modella e interpreta i cambiamenti
nelle strutture di cluster in diverse istantanee temporali dei dati. A
differenza dei metodi tradizionali di clustering statico, l'approccio proposto
cattura l'evoluzione dei cluster identificando le transizioni e fornendo
rappresentazioni interpretabili dei cambiamenti strutturali.

Il design modulare e agnostico rispetto all'algoritmo del framework ne facilita
l'applicazione a diversi domini e metodi di clustering. I risultati
sperimentali, ottenuti su dataset sintetici e reali, ne validano l'efficacia
nel migliorare la comprensione della dinamica dei dati, supportando così una
migliore adattabilità dei modelli di ML in contesti non stazionari.

Contribuendo alla spiegabilità del drift, questo lavoro mira a migliorare la
trasparenza e la robustezza delle applicazioni di ML che operano in ambienti
dinamici e complessi. \\ \\ \textbf{Parole chiave:} Machine Learning, Concept,
Non Stazionarietà, Clustering, Spiegabilità % Keywords (italian)
