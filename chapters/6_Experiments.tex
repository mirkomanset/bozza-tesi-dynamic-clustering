\chapter{Experiments}\label{ch:experiments}
This section provides detailed descriptions of each dataset used in the
experiments, outlining their origins, key characteristics, and preprocessing
procedures. The evaluation spans multiple data types including tabular, image,
and text data to comprehensively assess the performance of the dynamic
clustering algorithm across different modalities. For each dataset, the
clustering results produced by the dynamic clustering algorithm are presented
and analyzed, with particular emphasis on the interpretability and
explainability of the outcomes.

\section{Tabular data}\label{sec:tabular_data}

\subsection{Synthetic Data}\label{subsec:sythetic_data}

To assess the behavior of the proposed framework under controlled
non-stationary conditions, a synthetic dataset was generated. This dataset
simulates dynamic changes in cluster structure over time.

Each time step contains samples drawn from multivariate Gaussian distributions
in $\mathbb{R}^8$. The entire sequence consists of $20$ time steps, each
containing $100$ data points per active cluster. The generated stream evolves
smoothly, with transitions driven by interpolation and directional movement in
latent space.

The synthetic stream includes the following conceptual clusters:

\begin{itemize}
      \item \textbf{Cluster $ c_A $} (Fixed cluster): Present at every time step.
            This cluster remains stationary throughout the sequence, serving as a
            temporal anchor.

      \item \textbf{Clusters $ c_B $ and $ c_C $} (First merging pair): Initially
            positioned apart, these clusters move toward a common centroid during steps 0--4
            (merge phase), remain merged (identical means) during steps 5--9, and then split
            back to separate locations during steps 10--14.

      \item \textbf{Clusters $ c_D $ and $ c_E $} (Second merging pair): Unlike $ c_B $
            and $ c_C $, these clusters stay merged from the beginning of the stream until
            step 9. They then split into distinct clusters during steps 10--14 and gradually
            re-merge in steps 15--19.

      \item \textbf{Cluster $ c_F $} (Recurring cluster): Initially present in steps 0--4,
            this cluster disappears completely in steps 5--9. It reappears at step 10 and
            persists through step 14 before disappearing again in steps 15--19.

      \item \textbf{Cluster $ c_G $} (Appearing cluster): This cluster appears for
            the first time at step 15 and persists until the end of the stream (steps 15--19).
\end{itemize}

Each cluster is assigned a persistent label across all time steps, even during
periods of absence. The synthetic design provides explicit ground-truth
tracking information for evaluation. Additionally, random positive-definite
covariance matrices are assigned to each Gaussian component.

This synthetic dataset is designed to serve as a controlled benchmark for
testing the temporal coherence, memory mechanisms, and adaptability of dynamic
clustering algorithms under various non-stationary conditions.
\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/synthetic_data/best_setting/graph.png}
      \caption{Graphical evolution of Synthtic Data Experiment}
\end{figure}


\subsection{KDD Cup 99}\label{subsec:kdd_data}
The KDD Cup 1999 dataset~\cite{kdd99dataset} is a widely recognized benchmark
for evaluating intrusion detection systems (IDS) and machine learning
techniques in the cybersecurity domain. It was developed from network traffic
data collected during the DARPA 1998 Intrusion Detection Evaluation Program.
The dataset comprises millions of connection records, each labeled as either a
normal connection or one of 22 different attack types. Each instance is
represented by 41 features, which include both continuous numerical values and
symbolic (categorical) attributes

A widely used and more computationally manageable alternative to the full
dataset is the \textbf{10\% subset}, which contains approximately 494,021
records. This subset maintains the same feature structure and class
distribution as the original dataset. In this study, the 10\% subset is
employed to facilitate the application of dynamic clustering algorithms and to
ensure tractable processing times in an evolving data stream scenario.

To prepare the dataset for clustering, all categorical features were removed,
resulting in a set of 32 continuous numerical features. Subsequently, a Min-Max
normalization was applied to scale each feature into the range $[0,1]$,
standardizing the feature space and mitigating the impact of differing value
ranges on clustering algorithm.

The KDD99 dataset has been extensively used in the literature to evaluate the
performance of streaming and dynamic clustering algorithms in evolving
environments. Notable examples include \textsc{CluStream}~\cite{clustream},
\textsc{DenStream}~\cite{denstream}, \textsc{D-Stream}~\cite{d_stream}, and
\textsc{Stream\-KM++}~\cite{stream_km_plus_plus}.

In the context of dynamic clustering, each cluster can be interpreted as a
group of network connections exhibiting similar behavioral patterns. These
clusters may correspond to distinct categories of network activity such as:
Normal traffic, Denial of Service DoS (e.g., \emph{smurf}, \emph{neptune}),
User to Root U2R (e.g., \emph{buffer\_overflow}), Remote to Local R2L (e.g.,
\emph{guess\_passwd}) or Probing (e.g., \emph{nmap}, \emph{satan}).

\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/kdd_data/best_setting/graph.png}
      \caption{Graphical evolution of KDD-CUP-99 Data Experiment}
\end{figure}

\section{Images data}\label{sec:images_data}

\subsection{Brightness drift in places data}\label{subsec:brightness}

The dataset consists of images from the Places dataset~\cite{placesdataset},
focusing on two classes: \emph{mountain} and \emph{beach}. A reference set of
500 images per class is selected. Then, for each of 5 batches, 100 images per
class are sampled. In each batch, the brightness of the images is gradually
increased using color jitter to simulate smooth and unidirectional visual
drift.

Each image is resized to $224 \times 224$ pixels before being embedded using
the CLIP model~\cite{clip} to extract high-level feature representations. CLIP
(Contrastive Language-Image Pretraining) is a neural network model trained to
connect images and natural language descriptions in a shared embedding space.
It learns to encode images into feature vectors that capture semantic content
by contrasting image-text pairs during training, enabling effective zero-shot
classification and retrieval tasks.

Subsequently, the high-dimensional CLIP embeddings are reduced to 32 dimensions
using UMAP~\cite{umap} for computational efficiency and to facilitate
clustering. UMAP (Uniform Manifold Approximation and Projection) is a nonlinear
dimension reduction technique that preserves both local and global data
structure by constructing a high-dimensional graph and optimizing a
low-dimensional embedding to maintain the data's manifold structure, allowing
effective clustering and visualization.

This experimental setup evaluates the robustness of dynamic clustering methods
under smooth brightness drift affecting the global appearance of the input
images.

\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/image_brightness/best_setting/graph.png}
      \caption{Graphical evolution of Places-Brightness-Drift Experiment}
\end{figure}

\subsection{Fruits}\label{subsec:fruits}

A collected dataset of 2,420 RGB images of tangerines, each resized to $100
      \times 100$ pixels, was used to investigate dynamic clustering for images under
real-world conditions. Initially, the dataset contains predominantly green to
yellow tangerines, followed by the appearance of more orange and reddish
specimens. In addition to this chromatic progression, slight variations in
shape are also present. These gradual changes introduce distributional drift in
the visual domain, making the dataset a representative real case study for
evaluating the effectiveness of dynamic clustering methods.

To isolate the foreground objects and reduce background noise, automatic
background segmentation was applied using the GrabCut algorithm~\cite{grabcut}.
This technique leverages an iterative graph-cut procedure initialized with a
fixed bounding box to distinguish foreground from background, resulting in
4-channel RGBA images with transparent backgrounds.

Following segmentation, each image was encoded using a pretrained ResNet-50
convolutional neural network~\cite{resnet}, producing high-dimensional visual
feature embeddings. These embeddings were subsequently reduced to 64 dimensions
using UMAP~\cite{umap} to facilitate efficient clustering and visualization.
This experimental setup supports the analysis of cluster evolution in a
structured image dataset with visually similar objects exhibiting gradual
variations in color and background context.

\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/fruits/best_setting/graph.png}
      \caption{Graphical evolution of Fruits Images Experiment}
\end{figure}

\section{Text data}\label{sec:text_data}

\subsection{Typographical drift}\label{subsec:typographical_drift}
To evaluate the robustness of dynamic clustering under linguistic noise, a
subset of the 20 Newsgroups dataset~\cite{20newsgroups} was used, consisting of
four categories: \textit{rec.autos}, \textit{comp.graphics}, \textit{sci.med},
and \textit{rec.sport.baseball}. These categories represent distinct topics,
enabling clear cluster structure in the original space.

The experimental stream was constructed in two phases. Initially, 100 clean
documents per class were sampled to serve as a reference distribution.
Subsequently, for each of three drift stages, 278 documents per class were
sampled and subjected to varying levels of typographical corruption. The
corruption was introduced using a synthetic noise function designed to simulate
realistic typing errors through random character-level modifications, including
insertions, deletions, replacements, and swaps. The severity of corruption was
controlled by a parameter $\lambda \in \{0.1, 0.5, 0.9\}$, with higher values
producing more aggressive drift. Errors were constrained by keyboard proximity
rules to preserve plausibility.

Each text sample was embedded into a 384-dimensional semantic vector using the
\texttt{all\allowbreak-MiniLM\allowbreak-L6\allowbreak-v2}
model~\cite{sentence-transformers}, a transformer-based sentence encoder
optimized for efficient semantic representation. Dimensionality was
subsequently reduced to 32 using UMAP~\cite{umap} to facilitate clustering and
reduce computational overhead.

This setup emulates a realistic scenario in which textual input quality
degrades progressively while preserving underlying topical structure, offering
a controlled test for evaluating the temporal adaptability of clustering
algorithms.

\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/text_typos/best_setting/graph.png}
      \caption{Graphical evolution of Text Typos Experiment}
\end{figure}

\subsection{Topics Evolution}\label{subsec:topics_evolution}

To evaluate the behavior of dynamic clustering under topic distribution shifts,
a subset of the 20Newsgroups dataset~\cite{20newsgroups} was used. Four topical
categories were selected: \texttt{comp.graphics}, \texttt{rec.autos},
\texttt{sci.med}, and \texttt{rec.sport.hockey}, corresponding respectively to
labels $0$, $1$, $4$, and $3$. These topics represent distinct semantic areas
and were chosen to ensure adequate inter-class diversity.

Each document was embedded using the
\texttt{all\allowbreak-MiniLM\allowbreak-L6\allowbreak-v2}
model~\cite{sentence-transformers}, which produces compact and semantically
meaningful vector representations of text. The resulting high-dimensional
embeddings were then reduced to 16 dimensions using UMAP~\cite{umap} to enhance
computational efficiency and preserve cluster structures in a low-dimensional
space suitable for visualization and analysis.

A reference set was formed by sampling a fixed number of documents per topic
(e.g., 100 for \texttt{autos} and \texttt{med}, 50 for \texttt{graphics}).
Then, across eight batches (B1 to B8), topic proportions were deliberately
varied to simulate distribution shifts over time. This batch plan introduces
scenarios such as topic emergence, disappearance, and reappearance. For
instance, \texttt{rec.sport.hockey} (label 3) is entirely absent from the
reference and early batches but gradually increases in presence, peaking in
batch B7. Conversely, \texttt{rec.autos} (label 1) is prominent in the early
stages but vanishes completely in the last three batches.

\begin{table}[H]
      \centering
      \begin{tabular}{lccccccccc}
            \hline
            \textbf{Topic (Label)} & Ref & B1  & B2  & B3  & B4  & B5  & B6  & B7  & B8  \\
            \hline
            \texttt{graphics (0)}  & 50  & 100 & 100 & 50  & 50  & 50  & 0   & 100 & 100 \\
            \texttt{autos (1)}     & 100 & 100 & 100 & 100 & 50  & 50  & 0   & 0   & 0   \\
            \texttt{med (4)}       & 100 & 50  & 0   & 0   & 50  & 50  & 100 & 100 & 50  \\
            \texttt{hockey (3)}    & 0   & 0   & 50  & 100 & 100 & 100 & 150 & 50  & 100 \\
            \hline
      \end{tabular}
      \caption{Batch-wise Sample Distribution (per topic)}
\end{table}

\begin{figure}[h]
      \centering
      \includegraphics[width=1\textwidth]{my_images/experiment_results/text_topics/best_setting/graph.png}
      \caption{Graphical evolution of Text Topics Evolution Experiment}
\end{figure}