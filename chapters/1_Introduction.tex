\chapter{Introduction}\label{ch:introduction}

\section{Context}\label{sec:context}
In recent years, Machine Learning (ML) has emerged as a foundational technology
for addressing complex problems and extracting actionable insights from vast
and continuously expanding datasets. Industries such as finance, healthcare,
manufacturing, and fraud detection have integrated ML models into their core
decision-making processes. This integration is largely driven by advancements
in computing power, data storage capabilities, and the proliferation of
data-generating devices. These sectors are increasingly reliant on real-time
data streams originating from sensors, transactional systems, user
interactions, and external market sources.

In such dynamic settings, the ability to process and analyze data in real time
is essential. Stream-based learning allows models to adapt quickly to changing
conditions, allowing for timely and strategic intervention. Deploying and
maintaining machine learning models over time in production environments poses
substantial challenges. Among these challenges, one of the most persistent and
far-reaching is data nonstationarity—the phenomenon where the statistical
properties of data distributions evolve over time.

Most generalized machine learning algorithms operate under the implicit
assumption that data are independent and identically distributed (i.i.d.) and
drawn from a stationary distribution. However, this assumption rarely holds in
real-world applications. In practice, data distributions often shift or evolve
over time—a phenomenon known as \emph{drift}. If left unaddressed, drift can
significantly degrade a model's performance. Such drift can arise from various
factors, including gradual changes in user behavior, shifts in regulatory or
economic conditions, sensor degradation, software updates, or large-scale
events like global pandemics.

To address these challenges, the Machine Learning Operations
(MLOps)~\cite{mlops} paradigm has emerged as a comprehensive approach that
emphasizes automation, monitoring, and end-to-end management of machine
learning systems throughout their lifecycle. A central concern within MLOps is
ensuring that deployed models remain robust and reliable in the face of drift.

\section{Motivations}\label{sec:motivations}
Though various detection methods have been proposed for concept drift, most
existing solutions are likely to function as black-box systems, providing
little or no information regarding the cause or nature of the detected drift.
This lack of explainability poses a significant challenge in real-world
applications, where understanding the causes and nature of drift is essential
for making informed decisions and maintaining up-to-date models.

In most instances, determining when a drift has occurred is only the start. It
is equally important to know what type of drift has occurred and how it has
impacted the behavior of the model. Having knowledge that an event of drift has
occurred is not sufficient information upon which to make model adjustments.

Understanding the underlying causes of drift—such as shifts in data
distribution, emerging patterns, or changes in external factors—is essential
for developing effective retraining and maintenance strategies.

\section{Goals}\label{sec:goal}
The objective of this work is to design an explainability-driven monitoring
framework suitable for real-world streaming applications. The proposed method
leverages dynamic clustering to track and interpret structural changes in
incoming data, providing a human-interpretable view of input drift as it
unfolds. By continuously adapting to evolving data distributions, the framework
identifies shifts in cluster composition and formation, enabling a deeper
understanding of when and why drift occurs.

\section{Outline}\label{sec:outline}
Chapter~\ref{ch:preliminaries} introduces the key concepts such as Clustering
Stream Learning. It also covers Explainability in Machine Learning and defines
the various types of Drift. Techniques for Drift Detection, Adaptation, and
Explainability are also discussed.

Chapter~\ref{ch:problem_formulation} outlines the core research problems
addressed in this thesis, namely the Streaming Clustering Problem and the
Cluster Tracking Problem, highlighting the challenges they pose in dynamic
environments.

Chapter~\ref{ch:background} offers a comprehensive review of current methods in
Streaming Clustering and Cluster Tracking techniques highlighting their
strengths and limits.

Chapter~\ref{ch:method} introduces the proposed methodology, specifically
developed to tackle the challenges discussed in the preceding chapters.

Chapter~\ref{ch:experiments} describes the experimental setup, which includes
both synthetic and real-world datasets, to assess the effectiveness of the
proposed method in uncovering the causes of drift and explaining its underlying
dynamics.

Chapter~\ref{ch:conclusions} summarizes the key contributions and limitations
of the thesis. It also outlines relevant directions for future research aimed
at advancing the explainability and understanding of concept drift.