\chapter{Introduction}\label{ch:introduction}

\section{Context}\label{sec:context}
Machine Learning (ML) has become a foundational technology to solve hard issues
and construct usable information from large and continually growing bodies of
data over the last few years. Financial, health, manufacturing, and
fraud-detection industries have introduced ML models into core decision-making
systems, driven by advances in computing power, storage, and availability of
data-generating devices. These environments are increasingly dependent on the
real-time data streams that flow in from sensors, transactional systems, user
behavior, and external market feeds.

In such dynamic settings, the ability to process and analyze data in real time
is essential. Stream-based learning allows models to adapt quickly to changing
conditions, allowing for timely and strategic intervention. Deploying and
maintaining machine learning models over time in production environments poses
substantial challenges. Of them, one of the most enduring and far-reaching is
data nonstationarity, the way in which statistical properties of data
distributions change over time.

Most generalized machine learning algorithms operate under the implicit
assumption that data are independent and identically distributed (i.i.d.) and
drawn from a stationary distribution. However, this assumption rarely holds in
real-world applications. In practice, data distributions often shift or evolve
over time—a phenomenon known as concept drift. If left unaddressed, concept
drift can significantly degrade a model's performance. Such drift can arise
from various factors, including gradual changes in user behavior, shifts in
regulatory or economic conditions, sensor degradation, software updates, or
large-scale events like global pandemics.

To address these challenges, the Machine Learning Operations (MLOps) paradigm
has emerged as a comprehensive approach that emphasizes automation, monitoring,
and end-to-end management of machine learning systems throughout their
lifecycle. A central concern within MLOps is ensuring that deployed models
remain robust and reliable in the face of concept drift.

\section{Motivations}\label{sec:motivations}
Though various detection methods have been proposed for concept drift, most
existing solutions are likely to function as black-box systems, providing
little or no information regarding the cause or nature of the detected drift.
This lack of explainability poses a significant challenge in real-world
applications, where understanding the causes and nature of drift is essential
for making informed decisions and maintaining up-to-date models.

In most instances, determining when a drift has occurred is only the start. It
is equally important to know what type of drift has occurred and how it has
impacted the behavior of the model. Having knowledge that an event of drift has
occurred is not sufficient information upon which to make model adjustments.

Understanding the underlying causes of drift—such as shifts in data
distribution, emerging patterns, or changes in external factors—is essential
for developing effective retraining and maintenance strategies.

\section{Goals}\label{sec:goal}
The objective of this work is to design an explainability-driven monitoring
framework suitable for real-world streaming applications. The proposed method
leverages dynamic clustering to track and interpret structural changes in
incoming data, providing a human-interpretable view of input drift as it
unfolds. By continuously adapting to evolving data distributions, the framework
identifies shifts in cluster composition and formation, enabling a deeper
understanding of when and why drift occurs.

\section{Outline}\label{sec:outline}
Chapter~\ref{ch:preliminaries} introduces the key concepts such as Clustering
Stream Learning. It also covers Explainability in Machine Learning and defines
the various types of Drift. Techniques for Drift Detection, Adaptation, and
Explainability are also discussed.

Chapter~\ref{ch:problem_formulation} outlines the core research problems
addressed in this thesis, namely the Streaming Clustering Problem and the
Cluster Tracking Problem, highlighting the challenges they pose in dynamic
environments.

Chapter~\ref{ch:background} offers a comprehensive review of current methods in
Streaming Clustering and Cluster Tracking techniques highlighting their
strengths and limits.

Chapter~\ref{ch:method} introduces the proposed methodology, specifically
developed to tackle the challenges discussed in the preceding chapters.

Chapter~\ref{ch:experiments} describes the experimental setup, which includes
both synthetic and real-world datasets, to assess the effectiveness of the
proposed method in uncovering the causes of drift and explaining its underlying
dynamics.

Chapter~\ref{ch:conclusions} summarizes the key contributions and limitations
of the thesis. It also outlines relevant directions for future research aimed
at advancing the explainability and understanding of concept drift.